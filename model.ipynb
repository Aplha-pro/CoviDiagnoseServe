{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from joblib import dump\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = VGG19(weights='imagenet', include_top=False, input_shape=(128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(vgg19_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dense(units=3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_generator = ImageDataGenerator(\n",
    "    rescale= 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Covid-19/train'\n",
    "test_path = 'Covid-19/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_dataset = training_data_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_dataset = testing_data_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' , loss='categorical_crossentropy' , metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2826 - accuracy: 0.8765\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1964 - accuracy: 0.9084\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 25s 3s/step - loss: 0.1415 - accuracy: 0.9522\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 25s 3s/step - loss: 0.0953 - accuracy: 0.9721\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 26s 3s/step - loss: 0.0861 - accuracy: 0.9641\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 26s 3s/step - loss: 0.0769 - accuracy: 0.9801\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 28s 3s/step - loss: 0.0710 - accuracy: 0.9801\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 26s 3s/step - loss: 0.0745 - accuracy: 0.9681\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 25s 3s/step - loss: 0.0530 - accuracy: 0.9920\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 24s 3s/step - loss: 0.0576 - accuracy: 0.9880\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 25s 3s/step - loss: 0.0776 - accuracy: 0.9681\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 27s 3s/step - loss: 0.0441 - accuracy: 0.9920\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0524 - accuracy: 0.9801\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0480 - accuracy: 0.9801\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0463 - accuracy: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cd26c6f90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_dataset , epochs=15 , verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_testing_image(image_path, target_size=(128, 128)):\n",
    "    img = image.load_img(image_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0 \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Covid-19/test/Covid/COVID-00003b.jpg'\n",
    "preprocessed_img = preprocess_testing_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 323ms/step\n",
      "Predicted class: Covid\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(preprocessed_img)\n",
    "\n",
    "# Decode the prediction\n",
    "predicted_class = np.argmax(predictions)\n",
    "class_names = training_dataset.class_indices\n",
    "predicted_class_name = [k for k, v in class_names.items() if v == predicted_class][0]\n",
    "\n",
    "print(\"Predicted class:\", predicted_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained model.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model,'trained model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
